---
title: "Serving Inquiry 2/25"
author: "Jeremiah Burden"
date: "`r Sys.Date()`"
output: rmarkdown::github_document
---

# Analyzing JC MVB Serving

## Preprocessing
```{r}
pacman::p_load(tidyverse,ggrepel,rsample,caret,rattle,randomForest,pdp)
theme_set(theme_bw())

start_serve_data <- read_csv("/Users/jeremiahburden/Downloads/Volleyball/JCMVB Data/serving project/serve_data.csv")
```


Over the last 3 seasons, Juniata Men's Volleyball has collected over 5000 serves in order to improve our understanding of our serving performance. In this analysis, we focus on one particular server, Tyler Goldsborough, who has been our most effective server. Using data from this season, we build a model of his performance. 

While we collect 19 variables, we use 3 predictors. These are serve characteristics that are more controllable and we feel we can provide feedback on: the velocity in mph (`speed`), the zone the serve went to (`serve_destination`), and whether or not the serve landed between the passers (`seam`). These can be used to predict multiple responses, like how well the opponent passes the serve or whether or not the serve was an ace. Here, I choose to use whether or not we score the point (`point_score`) as a binary target.

```{r}
model_variables <- c("serve_destination","seam","speed","ace","point_score","xps")
serve_data <- start_serve_data %>% 
  filter(server=="Tyler G") %>% 
  filter(date > "2024-10-01") %>%
  filter(date < "2025-02-07") %>% 
  select(all_of(model_variables))
```

```{r}
str(serve_data)
dim(serve_data)
```
Since the start of the fall, we have over 100 serves that we've tracked to use for this model.

## EDA
I start by exploring the data by first looking at each of the variables individually before seeing their interplay.
```{r}
ggplot(serve_data, aes(x = serve_destination)) + geom_bar() + ggtitle("Serve Destination Distribution")
```
Tyler primarily serves where the zone 6 receiver passes.

```{r}
ggplot(serve_data, aes(x = seam)) + geom_bar() + ggtitle("Seam Serve Distribution")
```
He serves within the frame of passers about half the time.

```{r}
ggplot(serve_data, aes(x = speed)) + 
  geom_histogram(bins = 20) +
  geom_vline(aes(xintercept=mean(speed)),color="black")+
  geom_vline(aes(xintercept=median(speed)),color="red")+
  ggtitle("Serve Speed Distribution")
```
His serve speeds are slightly skewed left as his chop serve will go significantly slower than his top speed. This is shown in the slightly lower average speed than the median speed, skewed by the slower serves. 


Now, I begin looking at how each variable is related.

```{r}
ggplot(serve_data, aes(x = speed, y = point_score, color = as.factor(seam))) + 
  geom_jitter(alpha = 0.6) + ggtitle("Speed vs. Point Score by Seam")
```
There isn't a clear relationship between `speed` and `point_score`, but there seems to be more points scored than not above 60 mph. There doesn't seem to be a trend between `seam` and `speed`.

```{r}
ggplot(serve_data, aes(x = serve_destination, fill = as.factor(point_score))) + 
  geom_bar(position = "fill") + ggtitle("Point Score Rate by Serve Destination")
```
While he serves considerably less to zone 5, he has found tremendous success down the line (as he serves from zone 1), earning close to 75% of points. 

```{r}
serve_data %>%
  group_by(serve_destination, seam) %>%
  summarise(avg_ps = mean(point_score), 
            ace_rate = mean(ace), 
            avg_xps = mean(xps, na.rm = TRUE),
            avg_velo = mean(speed),
            n = n())
```
Unsurprisingly, he points scores more when he serves into the seam rather than in the frame of the passer. 


## Model Building
I build a random forest model using the `RandomForest` package because of its ability to use multiple variable types, reasonable predictive power, and the feature importance information available.

```{r}
serve_data <- serve_data %>%
  mutate(
    serve_destination = as.factor(serve_destination),
    seam = as.factor(seam),
    point_score = as.factor(point_score),  # classification model
    ace = as.factor(ace), 
    xps = factor(xps)  
  )
```
I first ensure all the variables are of the proper type.

I use 80% of the data to build the model, 20% to test, and then validate/apply on a recent match. 
```{r}
set.seed(2)
train_idx <- sample(nrow(serve_data), 0.8 * nrow(serve_data))
train_data <- serve_data[train_idx, ]
test_data <- serve_data[-train_idx, ]

rf_model <- randomForest(point_score ~ serve_destination + seam + speed, 
                         data = train_data, 
                         mtry = 2, 
                         importance = TRUE)

print(rf_model)  # Summary of accuracy
```
The model is reasonably accurate in predicting `point_score` given `serve_destination`, `seam`, and `speed`. By only using 2 of the variables at each split (not ideal with few feature types, but its best given the data I have), it allows each to influence the model.


Now, I test on the testing data to examine the model effectiveness and how much it overfit:
```{r}
test_pred <- predict(rf_model, test_data)
confusionMatrix(test_pred, test_data$point_score)
```
These test statistics are promising as the accuracy metrics are relatively high and there is clearly relationships identified (beyond random chance), according to the P-value. This is encouraging for the model, showing its utility. 



```{r}
varImpPlot(rf_model)
```
In predicting Ty's ability to break point, speed is most important, then the destination of the serve, and finally seam. I find it interesting that `seam` is last since in every case of success in the summary table above, it was more effective to serve in the seam than not. To me, this suggests that speed should be the most vital focus of feedback for Ty and we should identify what his optimal speed should be. Following, we would provide more information on the serve's destination.


Given this analysis, what speeds are best?
```{r}
pdp_speed <- partial(rf_model, pred.var = "speed", train = train_data)

ggplot(pdp_speed, aes(x = speed, y = yhat)) +
  geom_line(color = "red") +
  labs(title = "Effect of Serve Speed on Success",
       x = "Serve Speed (mph)",
       y = "Predicted Success Probability") +
  theme_minimal()
```
Interestingly, based solely on serve speed, there are a couple of speeds that stick out: just over 50 mph, which is his chop serve, his average speed between 55-59 mph, and his higher speeds at 63 mph and higher. These 3 really encapsulate the speeds he attempts to hit: a first serve around his average, then pick up the pace, then hit a chop serve after earning one. The model is intuitive to how he actually serves.


## Predicting optimal serve speed
In the past, I've used polynomial regression to identify optimal serve speeds. This novel method leverages the RF model to identify which serves are most effective. 
```{r}
test_serve_data <- expand.grid(
  serve_destination = unique(serve_data$serve_destination),
  seam = unique(serve_data$seam),
  speed = seq(min(serve_data$speed), max(serve_data$speed), length.out = 25)
)

test_serve_data$predicted_point <- predict(rf_model, test_serve_data, type = "prob")[,2]
```
First, I make a mock data set that has all the unique combinations of serves with many different speeds between his lowest and highest. Then, I use the model to predict whether or not the point would be scored using probability.


Then, I sort to show the most effective serves based on this predictive model.
```{r}
test_serve_data %>% arrange(desc(predicted_point))
```
Each of the top 28 serves in terms of predicted point are serves in the seam. While all zones are prevalent, zone 6 is most represented at the top, followed by zone 5. His most effective serves are between 60 and 67 mph according to this method. 

In terms of feedback, this suggests that asking Ty to focus on serving within this range to the middle of the court seams seems to produce the most effectiveness. There is also a somewhat limited data set, but is a unique way to identify serving effectiveness.

Now I seek to visualize serve effectiveness based on `speed` and `serve_destination`. 
```{r}
ggplot(test_serve_data, aes(x = speed, y = serve_destination, fill = predicted_point)) +
  geom_tile() +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  labs(title = "Serve Success Probability by Speed & Seam",
       x = "Serve Speed (mph)",
       y = "Seam",
       fill = "Success Probability")
```
This illustrates the success of serving above 60 mph straight ahead. Generally serving between 63-65 mph generates success in every zone. Ultimately, there is a higher service error rate at these higher speeds, indicated in the top row. 

I find it interesting that at his average speed, around 58 mph, he is generally ineffective, particularly to zone 6. That encourages a more aggressive serve initially, in my opinion.



## Applying to match data
Now, I want to examine how effective Ty's serving would be expected. Based on the data used, I want to see how effective he is in comparison to the past. Additionally, this can assess opponent passing.
```{r}
matchdata <- start_serve_data %>% 
  filter(server =="Tyler G") %>% 
  filter(date == "2025-02-07") %>% 
  select(all_of(model_variables))
  
matchdata <- matchdata %>% 
  mutate(
    serve_destination = as.factor(serve_destination),
    seam = as.factor(seam),
    point_score = as.factor(point_score),  # If binary, classification model
    ace = as.factor(ace), 
    xps = factor(xps)  # If continuous, use regression
  ) %>% 
  select(c("serve_destination","speed","seam","point_score")) %>% 
  mutate(
    serve_destination = ifelse(serve_destination == "2", "1", as.character(serve_destination))
  ) %>%
  mutate(serve_destination = as.factor(serve_destination))


ps_pred <- predict(rf_model, newdata = matchdata)
ps_prob <- predict(rf_model, newdata = matchdata,type="prob")
```

```{r}
conf_matrix <- table(ps_pred, matchdata$point_score)
print(conf_matrix)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
print(paste("Accuracy:", accuracy))
ps_df <- bind_cols(matchdata, ps_pred, ps_prob) 

x_model_ps <- ps_df %>% 
  summarize(xMPS = sum(`1`),
            ps= sum(as.numeric(point_score)==1),
            n=n())
x_model_ps
```
Although the accuracy for the model is somewhat low overall at 60%, the model predicts that the total probability of earning points is about 11, which is how many he earned in the match. Interestingly, the model is quite effective!

This would suggest that Ty earned points exactly how we would expect based on his past performance and that the receive passed about how we would expect given our data. That is useful feedback and can be done with how well they actually pass the ball (expected point scoring) as well.



# Takeaways
(1) This analysis shows how things that are intuitive to expert practitioners (things Ty and our coaching staff have already identified), are reflected in the data. 
  - Serving in the seam is more effective than not.
  - Serving success is reflected in how you train it (the success of Ty's speeds are shown in how we talk about first, second and third serves)
(2) The magnitude of these relationships are revealed
 - Intuitively, serving in the seam makes sense. But seeing that Ty's best 30 serves are more effective if they are in the seam than if they are not, illuminate how important it is.
(3) Leveraging machine learning models and rethinking problems can yield novel explanations and results.

